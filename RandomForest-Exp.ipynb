{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "df_train=pd.read_csv(\"train.csv\",encoding='latin-1')\n",
    "df_test=pd.read_csv(\"test.csv\",encoding='latin-1')\n",
    "#attributes=pd.read_csv(\"attributes.csv\",encoding='latin-1')\n",
    "df_pro_desc=pd.read_csv(\"product_descriptions.csv\",encoding='latin-1')\n",
    "num_train = df_train.shape[0]\n",
    "#df_train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def str_stemmer(s):\n",
    "#\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_stemmer(x):\n",
    "    for word in x.lower().split():\n",
    "        return stemmer.stem(x)\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "def remove_stopwords(text, lang='english'):\n",
    "    words = word_tokenize(text)\n",
    "    stopw = stopwords.words(lang)\n",
    "    stopw_removed = [word for word in words if word.lower() not in stopw]\n",
    "    return \" \".join(stopw_removed)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "    return \" \".join(punt_removed)\n",
    "\n",
    "def another_stem(s): \n",
    "    if isinstance(s, str):\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"'\",\"in.\") \n",
    "        s = s.replace(\"inches\",\"in.\") \n",
    "        s = s.replace(\"inch\",\"in.\")\n",
    "        s = s.replace(\" in \",\"in. \") \n",
    "        s = s.replace(\" in.\",\"in.\") \n",
    "        s = s.replace(\"''\",\"ft.\") \n",
    "        s = s.replace(\" feet \",\"ft. \") \n",
    "        s = s.replace(\"feet\",\"ft.\") \n",
    "        s = s.replace(\"foot\",\"ft.\") \n",
    "        s = s.replace(\" ft \",\"ft. \") \n",
    "        s = s.replace(\" ft.\",\"ft.\") \n",
    "    \n",
    "        s = s.replace(\" pounds \",\"lb. \")\n",
    "        s = s.replace(\" pound \",\"lb. \") \n",
    "        s = s.replace(\"pound\",\"lb.\") \n",
    "        s = s.replace(\" lb \",\"lb. \") \n",
    "        s = s.replace(\" lb.\",\"lb.\") \n",
    "        s = s.replace(\" lbs \",\"lb. \") \n",
    "        s = s.replace(\"lbs.\",\"lb.\") \n",
    "\n",
    "        s = s.replace(\" x \",\" xby \")\n",
    "        s = s.replace(\"*\",\" xby \")\n",
    "        s = s.replace(\" by \",\" xby\")\n",
    "        s = s.replace(\"x0\",\" xby 0\")\n",
    "        s = s.replace(\"x1\",\" xby 1\")\n",
    "        s = s.replace(\"x2\",\" xby 2\")\n",
    "        s = s.replace(\"x3\",\" xby 3\")\n",
    "        s = s.replace(\"x4\",\" xby 4\")\n",
    "        s = s.replace(\"x5\",\" xby 5\")\n",
    "        s = s.replace(\"x6\",\" xby 6\")\n",
    "        s = s.replace(\"x7\",\" xby 7\")\n",
    "        s = s.replace(\"x8\",\" xby 8\")\n",
    "        s = s.replace(\"x9\",\" xby 9\")\n",
    "        s = s.replace(\"0x\",\"0 xby \")\n",
    "        s = s.replace(\"1x\",\"1 xby \")\n",
    "        s = s.replace(\"2x\",\"2 xby \")\n",
    "        s = s.replace(\"3x\",\"3 xby \")\n",
    "        s = s.replace(\"4x\",\"4 xby \")\n",
    "        s = s.replace(\"5x\",\"5 xby \")\n",
    "        s = s.replace(\"6x\",\"6 xby \")\n",
    "        s = s.replace(\"7x\",\"7 xby \")\n",
    "        s = s.replace(\"8x\",\"8 xby \")\n",
    "        s = s.replace(\"9x\",\"9 xby \")\n",
    "    \n",
    "        s = s.replace(\" sq ft\",\"sq.ft. \") \n",
    "        s = s.replace(\"sq ft\",\"sq.ft. \")\n",
    "        s = s.replace(\"sqft\",\"sq.ft. \")\n",
    "        s = s.replace(\" sqft \",\"sq.ft. \") \n",
    "        s = s.replace(\"sq. ft\",\"sq.ft. \") \n",
    "        s = s.replace(\"sq ft.\",\"sq.ft. \") \n",
    "        s = s.replace(\"sq feet\",\"sq.ft. \") \n",
    "        s = s.replace(\"square feet\",\"sq.ft. \") \n",
    "    \n",
    "        s = s.replace(\" gallons \",\"gal. \") \n",
    "        s = s.replace(\" gallon \",\"gal. \") \n",
    "        s = s.replace(\"gallons\",\"gal.\") \n",
    "        s = s.replace(\"gallon\",\"gal.\") \n",
    "        s = s.replace(\" gal \",\"gal. \") \n",
    "        s = s.replace(\" gal\",\"gal.\") \n",
    "\n",
    "        s = s.replace(\"ounces\",\"oz.\")\n",
    "        s = s.replace(\"ounce\",\"oz.\")\n",
    "        s = s.replace(\" oz.\",\"oz. \")\n",
    "        s = s.replace(\" oz \",\"oz. \")\n",
    "\n",
    "        s = s.replace(\"centimeters\",\"cm.\")    \n",
    "        s = s.replace(\" cm.\",\"cm.\")\n",
    "        s = s.replace(\" cm \",\"cm. \")\n",
    "        \n",
    "        s = s.replace(\"wayy\", \"way\")\n",
    "        s = s.replace(\"milimeters\",\"mm.\")\n",
    "        s = s.replace(\" mm.\",\"mm.\")\n",
    "        s = s.replace(\" mm \",\"mm. \")\n",
    "        \n",
    "        s = s.replace(\"Â°\",\"deg. \")\n",
    "        s = s.replace(\"degrees\",\"deg. \")\n",
    "        s = s.replace(\"degree\",\"deg. \")\n",
    "        \n",
    "        s = s.replace(\"volts\",\"volt. \")\n",
    "        s = s.replace(\"volt\",\"volt. \")\n",
    "\n",
    "        s = s.replace(\"watts\",\"watt. \")\n",
    "        s = s.replace(\"watt\",\"watt. \")\n",
    "\n",
    "        s = s.replace(\"ampere\",\"amp. \")\n",
    "        s = s.replace(\"amps\",\"amp. \")\n",
    "        s = s.replace(\" amp \",\"amp. \")\n",
    "        \n",
    "        s = s.replace(\"whirpool\",\"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolga\", \"whirlpool\")\n",
    "        s = s.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        \n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        return s.lower()\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owned\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck over</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      product_title  product_uid  \\\n",
       "0   2                  Simpson Strong-Tie 12-Gauge Angle       100001   \n",
       "1   3                  Simpson Strong-Tie 12-Gauge Angle       100001   \n",
       "2   9  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...       100002   \n",
       "3  16  Delta Vero 1-Handle Shower Only Faucet Trim Ki...       100005   \n",
       "4  17  Delta Vero 1-Handle Shower Only Faucet Trim Ki...       100005   \n",
       "\n",
       "   relevance         search_term  \\\n",
       "0       3.00       angle bracket   \n",
       "1       2.50           l bracket   \n",
       "2       3.00           deck over   \n",
       "3       2.33    rain shower head   \n",
       "4       2.67  shower only faucet   \n",
       "\n",
       "                                 product_description  \n",
       "0  Not only do angles make joints stronger, they ...  \n",
       "1  Not only do angles make joints stronger, they ...  \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...  \n",
       "3  Update your bathroom with the Delta Vero Singl...  \n",
       "4  Update your bathroom with the Delta Vero Singl...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>len_of_query</th>\n",
       "      <th>word_in_title</th>\n",
       "      <th>word_in_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid  relevance  len_of_query  word_in_title  \\\n",
       "0   2       100001       3.00             2              1   \n",
       "1   3       100001       2.50             2              1   \n",
       "2   9       100002       3.00             2              2   \n",
       "3  16       100005       2.33             3              1   \n",
       "4  17       100005       2.67             2              2   \n",
       "\n",
       "   word_in_description  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    2  \n",
       "3                    1  \n",
       "4                    2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming activity\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:remove_stopwords(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:remove_stopwords(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:remove_stopwords(x))\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:remove_punctuations(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:remove_punctuations(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:remove_punctuations(x))\n",
    "\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:another_stem(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:another_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:another_stem(x))\n",
    "\n",
    "#Add length of query column\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "#Add a product_info column summarizing attributes\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "#Add two columns to find No of common words\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "#Drop the old ones\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape matching\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train x,y\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressors used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if 3>4:\n",
    "    param_grid = {\n",
    "                'loss' : ['ls'],\n",
    "                'n_estimators' : [3], \n",
    "                'max_depth' : [9],\n",
    "                'max_features' : ['auto']  }\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "    model_gbr = sklearn.model_selection.GridSearchCV(estimator = gbr, n_jobs = -1, param_grid = param_grid)\n",
    "    model_gbr.fit(X_train, y_train)\n",
    "    y_pred = model_gbr.predict(X_test)\n",
    "    \n",
    "    \n",
    "if 3<4:\n",
    "    rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "    clf = BaggingRegressor(rf, n_estimators=55, max_samples=0.1, random_state=25)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "if 3>4:\n",
    "    lss = linear_model.Lasso(alpha=0.1)\n",
    "    lss.fit(X_train, y_train)\n",
    "    y_pred = lss.predict(X_test)\n",
    "    \n",
    "if 3>4:\n",
    "    \n",
    "    gnb = BayesianRidge()\n",
    "    param_grid = {}\n",
    "    model_nb = sklearn.model_selection.GridSearchCV(estimator = gnb, param_grid = param_grid, n_jobs = -1)\n",
    "    model_nb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 3<4:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train, y_train)\n",
    "    scaled_train_data = scaler.transform(X_train)\n",
    "    scaled_test_data = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=200, max_depth=6, random_state=0)\n",
    "    clf = BaggingRegressor(rf, n_estimators=200, max_samples=0.1, random_state=25)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [('scaling', scaler), ('baggingregressor', clf)])\n",
    "    #end pipeline \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  16 | elapsed:   24.7s remaining:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  16 | elapsed:   24.9s remaining:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  16 | elapsed:   25.2s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  16 | elapsed:   36.3s remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:   36.5s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   37.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   37.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_samples': 0.1, 'n_estimators': 55, 'random_state': 25}\n",
      "Best CV score:\n",
      "-0.49110167384650333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "\n",
    "RMSE  = make_scorer(fmean_squared_error, greater_is_better=False)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [0.1,0.2],\n",
    "    'random_state':[15,25],\n",
    "    'n_estimators':[45,55]\n",
    "}\n",
    "model = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 2, verbose = 20, scoring=RMSE)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('Rfexp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3fd9b1939623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-8362592d5514>\u001b[0m in \u001b[0;36mfactorial\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m<ipython-input-22-8362592d5514>\u001b[0m in \u001b[0;36mfactorial\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
